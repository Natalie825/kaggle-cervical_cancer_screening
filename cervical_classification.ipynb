{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intel Cervical Cancer Screening\n",
    "### April 21, 2017\n",
    "## Satchel Grant\n",
    "\n",
    "### Overview\n",
    "The goal of this notebook is to classify a woman's cervical type into 1 of 3 classes from medical imaging data. This assists in determination of cancer diagnoses and treatments.\n",
    "\n",
    "### Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import scipy.misc as sci\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Data\n",
    "The images are stored as jpg files, stored in folders corresponding to their classification. I read in the image os paths to be converted to images later in batches. I store their classification in a parallel array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples: 1481\n",
      "Number of Classes: 3\n"
     ]
    }
   ],
   "source": [
    "root_path = './train/'\n",
    "\n",
    "def read_paths(path, no_labels=False):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    labels_to_nums = dict()\n",
    "    for dir_name, subdir_list, file_list in os.walk(path):\n",
    "        if len(subdir_list) > 0:\n",
    "            n_labels = len(subdir_list)\n",
    "            for i,subdir in enumerate(subdir_list):\n",
    "                labels_to_nums[subdir] = i\n",
    "        else:\n",
    "            type_ = dir_name.split('/')[-1]\n",
    "        for img_file in file_list:\n",
    "            if '.jpg' in img_file.lower():\n",
    "                file_paths.append(os.path.join(dir_name,img_file))\n",
    "                if no_labels: labels.append(img_file)\n",
    "                else: labels.append(labels_to_nums[type_])\n",
    "    return file_paths, labels, n_labels\n",
    "    \n",
    "\n",
    "image_paths, labels, n_labels = read_paths(root_path)\n",
    "image_paths, labels = shuffle(image_paths, labels)\n",
    "\n",
    "print(\"Number of data samples: \" + str(len(image_paths)))\n",
    "print(\"Number of Classes: \" + str(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a relatively small number of samples to use for deep learning... Luckily Kaggle provided more samples than just those in the train set. I will read those in as well after initial prototyping is finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "The following cells add rotations and translations to the dataset. This increases the number of samples for training which helps the model generalize better. This prevents overfitting the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(image, angle, ones, color_range):\n",
    "    rot_image = sci.imrotate(image, angle).astype(np.float32)\n",
    "    edge_filler = np.random.random(rot_image.shape).astype(np.float32)*color_range\n",
    "    rot_image[ones[:,:,:]!=1] = edge_filler[ones[:,:,:]!=1]\n",
    "    return rot_image\n",
    "\n",
    "def translate(image, row_shift, col_shift, color_range):\n",
    "    trans_image = np.random.random(image.shape).astype(np.float32)*color_range\n",
    "    if row_amt > 0:\n",
    "        if col_amt > 0:\n",
    "            translation[row_amt:,col_amt:] = img[:-row_amt,:-col_amt]\n",
    "        elif col_amt < 0:\n",
    "            translation[row_amt:,:col_amt] = img[:-row_amt,-col_amt:]\n",
    "        else:\n",
    "            translation[row_amt:,:] = img[:-row_amt,:]\n",
    "    elif row_amt < 0:\n",
    "        if col_amt > 0:\n",
    "            translation[:row_amt,col_amt:] = img[-row_amt:,:-col_amt]\n",
    "        elif col_amt < 0:\n",
    "            translation[:row_amt,:col_amt] = img[-row_amt:,-col_amt:]\n",
    "        else:\n",
    "            translation[:row_amt,:] = img[-row_amt:,:]\n",
    "    else:\n",
    "        if col_amt > 0:\n",
    "            translation[:,col_amt:] = img[:,:-col_amt]\n",
    "        elif col_amt < 0:\n",
    "            translation[:,:col_amt] = img[:,-col_amt:]\n",
    "        else:\n",
    "            return img.copy()\n",
    "    return translation\n",
    "\n",
    "def add_augmentations(paths, rot_angles=[10,-10], row_shift=15, col_shift=15):\n",
    "    img = mpimg.imread(paths[0])\n",
    "    ones = [sci.imrotate(np.ones_like(img),rot_angles[i]) for i in range(len(rot_angles))]\n",
    "    for path in paths:\n",
    "        img = mpimg.imread(path)\n",
    "        for i,angle in enumerate(rot_angles):\n",
    "            add_augmentation(img,path,angle,row_shift,col_shift,ones[i])\n",
    "\n",
    "def add_augmentation(img,path,angle,row_shift,col_shift,ones):\n",
    "    color_range = 255\n",
    "    new_img = rotate(img,angle,ones, color_range)\n",
    "    new_img = translate(new_img,random.randint(-row_shift,row_shift),random.randint(-col_shift,col_shift), color_range)\n",
    "    new_img = new_img.astype(np.uint8)\n",
    "    split_path = path.split('/')\n",
    "    i = 1\n",
    "    if angle < 0: i = 2\n",
    "    split_path[-1] = 'augmented_'+ str(i)+\"_\"+ split_path[-1]\n",
    "    new_path = '/'.join(split_path)\n",
    "    jpeg = Image.fromarray(new_img)\n",
    "    jpeg.save(new_path)\n",
    "\n",
    "\n",
    "def one_hot_encode(labels, n_classes):\n",
    "    one_hots = []\n",
    "    for label in labels:\n",
    "        one_hot = [0]*n_classes\n",
    "        one_hot[label] = 1\n",
    "        one_hots.append(one_hot)\n",
    "    return np.array(one_hots,dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Validation Sets\n",
    "It is important to set aside images for validation. This is how you can determine if your model is overfitting or underfitting during training.\n",
    "\n",
    "Since I am completing this notebook over the course of multiple days, I save the training paths and validation paths into seperate csv files along with their classification. This is essentially a checkpoint step so that it is easy to repeatedly save and restore the weights of the model later in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_percentage = .75\n",
    "total_samples = len(image_paths)\n",
    "split_index = int(training_percentage*total_samples)\n",
    "\n",
    "X_train_paths, y_train = image_paths[:split_index], labels[:split_index]\n",
    "X_valid_paths, y_valid = image_paths[split_index:], labels[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples: 1110\n",
      "Number of Validation Samples: 371\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Training Samples: \" + str(len(y_train)))\n",
    "print(\"Number of Validation Samples: \" + str(len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_paths(file_name, paths, labels):\n",
    "    with open(file_name, 'w') as csv_file:\n",
    "        for path,label in zip(paths,labels):\n",
    "            csv_file.write(path + ',' + str(label) + '\\n')\n",
    "\n",
    "save_paths('train_set.csv', X_train_paths, y_train)\n",
    "save_paths('valid_set.csv', X_valid_paths, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Image Reader\n",
    "To maximize memory, the images for both testing and training can be read in in batches. This increases the amount of images that can be trained on in a single epoch which helps the model generalize. In most cases, more training data is better for deep learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_images(paths,resize_dims=None):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = mpimg.imread(path).astype(np.float32)\n",
    "        print(img.shape)\n",
    "        if resize_dims:\n",
    "            img = sci.imresize(img, resize_dims)\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "def image_generator(paths, labels, batch_size, resize_dims=None):\n",
    "    while True:\n",
    "        for batch in range(0,len(paths),batch_size):\n",
    "            image_batch = convert_images(paths[batch:batch+batch_size])\n",
    "            label_batch = labels[batch:batch+batch_size]\n",
    "            yield image_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notbook on pause to learn about recurrent neural networks. \n",
    "\n",
    "The cervical images are of different sizes. I'm currently unsure of image is required for resizing. RNNs can be used to find specific objects within the picture. Potentially I could run an RNN to find the appropriate cropping diminsions for the image and then resize apporopriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3264, 2448, 3)\n",
      "(4128, 3096, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fbd3d884b61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mshow_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-2ebd9ebd7b64>\u001b[0m in \u001b[0;36mimage_generator\u001b[0;34m(paths, labels, batch_size, resize_dims)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mimage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-2ebd9ebd7b64>\u001b[0m in \u001b[0;36mconvert_images\u001b[0;34m(paths, resize_dims)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "image_gen = image_generator(image_paths[:10], labels[:10], 2)\n",
    "for i in range(5):\n",
    "    imgs, labels = next(image_gen)\n",
    "    show_img(imgs[0])\n",
    "    print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
